{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# *Merged Jupyter Notebook*"]}, {"cell_type": "markdown", "metadata": {}, "source": "<hr><font color=\"green\"><h1>from file: 02_02_Format_Data</h1></font>"}, {"cell_type": "markdown", "metadata": {}, "source": ["# How to Format Data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Scikit-learn is a great library for creating machine learning models from data. Before you can fit a model using scikit-learn, your data has to be in a recognizable format. Scikit-learn works well with numeric data that is stored in numpy arrays. Additionally, you can convert your data from objects like pandas dataframes to numpy arrays. In this video, I'll show you how you make your data a more acceptable input for scikit-learn. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Features Matrix and Target Vector\n", "\n", "The first thing you have to understand is what Scikit-Learn expects for Features Matrices and target vectors. In scikit-learn, a features matrix is a two-dimensional grid of data where rows represent samples and columns represent features. A target vector is usually one dimensional and in the case of supervised learning, what you want to predict from the data. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["![images](images/featuresMatrixTargetVector.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's see an example of this. the image is a pandas dataframe of the first 5 rows of the iris dataset. A single flower represent one row of the dataset and the flower measurements are the columns. In this dataset, the species column is what you are trying to predict. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["![images](images/irisFeatureTarget.png)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's now go over how to make sure your data is in an acceptable format"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Import Libraries"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["%matplotlib inline\n", "\n", "import matplotlib.pyplot as plt\n", "import pandas as pd\n", "\n", "from sklearn.datasets import load_iris"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load the Dataset\n", "The Iris dataset is one of datasets scikit-learn comes with that do not require the downloading of any file from some external website. The code below loads the iris dataset."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>sepal length (cm)</th>\n", "      <th>sepal width (cm)</th>\n", "      <th>petal length (cm)</th>\n", "      <th>petal width (cm)</th>\n", "      <th>species</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>5.1</td>\n", "      <td>3.5</td>\n", "      <td>1.4</td>\n", "      <td>0.2</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>4.9</td>\n", "      <td>3.0</td>\n", "      <td>1.4</td>\n", "      <td>0.2</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>4.7</td>\n", "      <td>3.2</td>\n", "      <td>1.3</td>\n", "      <td>0.2</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>4.6</td>\n", "      <td>3.1</td>\n", "      <td>1.5</td>\n", "      <td>0.2</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>5.0</td>\n", "      <td>3.6</td>\n", "      <td>1.4</td>\n", "      <td>0.2</td>\n", "      <td>0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n", "0                5.1               3.5                1.4               0.2   \n", "1                4.9               3.0                1.4               0.2   \n", "2                4.7               3.2                1.3               0.2   \n", "3                4.6               3.1                1.5               0.2   \n", "4                5.0               3.6                1.4               0.2   \n", "\n", "   species  \n", "0        0  \n", "1        0  \n", "2        0  \n", "3        0  \n", "4        0  "]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["data = load_iris()\n", "df = pd.DataFrame(data.data, columns=data.feature_names)\n", "df['species'] = data.target\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Arrange Data into Features Matrix and Target Vector"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["feature_names = ['sepal length (cm)',\n", "                 'sepal width (cm)',\n", "                 'petal length (cm)',\n", "                 'petal width (cm)']"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>sepal length (cm)</th>\n", "      <th>sepal width (cm)</th>\n", "      <th>petal length (cm)</th>\n", "      <th>petal width (cm)</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>5.1</td>\n", "      <td>3.5</td>\n", "      <td>1.4</td>\n", "      <td>0.2</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>4.9</td>\n", "      <td>3.0</td>\n", "      <td>1.4</td>\n", "      <td>0.2</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>4.7</td>\n", "      <td>3.2</td>\n", "      <td>1.3</td>\n", "      <td>0.2</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>4.6</td>\n", "      <td>3.1</td>\n", "      <td>1.5</td>\n", "      <td>0.2</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>5.0</td>\n", "      <td>3.6</td>\n", "      <td>1.4</td>\n", "      <td>0.2</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>145</th>\n", "      <td>6.7</td>\n", "      <td>3.0</td>\n", "      <td>5.2</td>\n", "      <td>2.3</td>\n", "    </tr>\n", "    <tr>\n", "      <th>146</th>\n", "      <td>6.3</td>\n", "      <td>2.5</td>\n", "      <td>5.0</td>\n", "      <td>1.9</td>\n", "    </tr>\n", "    <tr>\n", "      <th>147</th>\n", "      <td>6.5</td>\n", "      <td>3.0</td>\n", "      <td>5.2</td>\n", "      <td>2.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>148</th>\n", "      <td>6.2</td>\n", "      <td>3.4</td>\n", "      <td>5.4</td>\n", "      <td>2.3</td>\n", "    </tr>\n", "    <tr>\n", "      <th>149</th>\n", "      <td>5.9</td>\n", "      <td>3.0</td>\n", "      <td>5.1</td>\n", "      <td>1.8</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>150 rows \u00c3\u2014 4 columns</p>\n", "</div>"], "text/plain": ["     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n", "0                  5.1               3.5                1.4               0.2\n", "1                  4.9               3.0                1.4               0.2\n", "2                  4.7               3.2                1.3               0.2\n", "3                  4.6               3.1                1.5               0.2\n", "4                  5.0               3.6                1.4               0.2\n", "..                 ...               ...                ...               ...\n", "145                6.7               3.0                5.2               2.3\n", "146                6.3               2.5                5.0               1.9\n", "147                6.5               3.0                5.2               2.0\n", "148                6.2               3.4                5.4               2.3\n", "149                5.9               3.0                5.1               1.8\n", "\n", "[150 rows x 4 columns]"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["# Multiple column features matrix to convert to NumPy Array\n", "df.loc[:, feature_names]"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# Convert to numpy array\n", "x = df.loc[:, feature_names].values"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"data": {"text/plain": ["(150, 4)"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["# Make sure NumPy array is two dimensional\n", "x.shape"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"data": {"text/plain": ["0      0\n", "1      0\n", "2      0\n", "3      0\n", "4      0\n", "      ..\n", "145    2\n", "146    2\n", "147    2\n", "148    2\n", "149    2\n", "Name: species, Length: 150, dtype: int32"]}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": ["# Pandas series to convert to NumPy Array\n", "df.loc[:, 'species']"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["y = df.loc[:, 'species'].values"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"data": {"text/plain": ["(150,)"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["y.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["So that's it, scikit-learn expects data in a particular format. "]}, {"cell_type": "markdown", "metadata": {}, "source": "<hr><font color=\"green\"><h1>from file: 02_03_Linear_Regression</h1></font>"}, {"cell_type": "markdown", "metadata": {}, "source": ["How do you create a complex model using scikit-learn? An easy solution is to start with a simple model like linear regression and go from there.\n", "\n", "![image](images/linearregression.png)\n", "\n", "In this video, I'll show you can create a linear regression model using Scikit-Learn so that more complex models will be easier to create\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Import Libraries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%matplotlib inline\n", "\n", "import matplotlib.pyplot as plt\n", "import pandas as pd\n", "\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LinearRegression"]}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": ["## Load the Dataset\n", "The dataset that is loaded below is a dataset which is designed to show that Scikit-Learn requires data to be free of missing values. If you don't remove or impute your missing values, you will get an error. The goal of this dataset is to use the feature column x to predict the target column y. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"data/linear.csv\")\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##  Remove Missing or Impute Values\n", "If you want to build models with your data, null values are (almost) never allowed. It is important to always see how many samples have missing values and for which columns."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Look at the shape of the dataframe\n", "df.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# There are missing values in the y column which is what we will predict \n", "df.isnull().sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You can either remove rows where there is a missing value or you can fill in missing values. The option used in this notebook is to remove rows with missing values. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Remove entire rows from dataframe if they contain any nans in them or 'all'\n", "# this may not be the best strategy for our dataset\n", "df = df.dropna(how = 'any')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# There are no more missing values\n", "df.isnull().sum()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You could have filled in missing values using the `fillna` method on a pandas series if you want"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Arrange Data into Features Matrix and Target Vector"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Convert x column to numpy array\n", "X = df.loc[:, ['x']].values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Features Matrix needs to be at 2 dimensional\n", "X.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y = df.loc[:, 'y'].values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Linear Regression\n", "\n", "<b>Step 1:</b> Import the model you want to use\n", "\n", "In sklearn, all machine learning models are implemented as Python classes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# This was already imported earlier in the notebook so commenting out\n", "#from sklearn.linear_model import LinearRegression"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<b>Step 2:</b> Make an instance of the Model\n", "\n", "This is a place where you can tune the hyperparameters of a model. In the case of linear regression, you can set `fit_intercept` to True or False depending on your needs. This is an important concept as more complex models have a lot more you can tune. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["![images](images/regInterceptTrueFalse.png)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Make a linear regression instance\n", "reg = LinearRegression(fit_intercept=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# If you want to see what you can tune for a model, you can use the help function\n", "#help(LinearRegression)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<b>Step 3:</b> Training the model on the data, storing the information learned from the data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Model is learning the relationship between x and y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["reg.fit(X,y)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<b>Step 4:</b> Predict the values of new data. Uses the information the model learned during the model training process"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predict for One Observation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Input needs to be two dimensional (reshape makes input two dimensional )\n", "reg.predict(X[0].reshape(-1,1))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predict for Multiple Observations at Once"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["reg.predict(X[0:10])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Measuring Model Performance"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Unlike classification models where a common metric is accuracy, regression models use other metrics like R^2, the coefficient of determination to quantify your model's performance. The best possible score is 1.0. A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["score = reg.score(X, y)\n", "print(score)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## What is the equation of the line for the regression?\n", "\n", "After you fit an instance of a model in scikit-learn, you can use additional attributes. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["reg.coef_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["reg.intercept_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["m = reg.coef_[0]\n", "\n", "b = reg.intercept_\n", "\n", "# following slope intercept form \n", "print(\"formula: y = {:.2f}x + {:.2f}\".format(m, b) )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Plotting the Best Fit Linear Regression Line in Red"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (10,7));\n", "\n", "ax.scatter(X, y, color='black');\n", "ax.plot(X, reg.predict(X), color='red',linewidth=3);\n", "ax.grid(True,\n", "        axis = 'both',\n", "        zorder = 0,\n", "        linestyle = ':',\n", "        color = 'k')\n", "ax.tick_params(labelsize = 18)\n", "ax.set_xlabel('x', fontsize = 24)\n", "ax.set_ylabel('y', fontsize = 24)\n", "ax.set_title(\"Linear Regression Line with Intercept y = {:.2f}x + {:.2f} (R2 = {:.2f})\".format(m, b, score), fontsize = 16 )\n", "fig.tight_layout()\n", "#fig.savefig('images/linearregression', dpi = 300)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Plotting Models With or Without Intercept\n", "In this section, you will see how changing a hyperparameter value can have a drastic impact on the R2 "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Model with Intercept (like earlier in notebook)\n", "reg_inter = LinearRegression(fit_intercept=True)\n", "reg_inter.fit(X,y)\n", "predictions_inter = reg_inter.predict(X)\n", "score_inter = reg_inter.score(X, y)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10,7));\n", "\n", "for index, model in enumerate([LinearRegression(fit_intercept=True), LinearRegression(fit_intercept=False)]): \n", "    model.fit(X,y)\n", "    predictions = model.predict(X)\n", "    score = model.score(X, y)\n", "    m = model.coef_[0]\n", "    b = model.intercept_\n", "    \n", "    ax[index].scatter(X, y, color='black');\n", "    ax[index].plot(X, model.predict(X), color='red',linewidth=3);\n", "\n", "    ax[index].tick_params(labelsize = 18)\n", "    ax[index].set_xlabel('x', fontsize = 18)\n", "    ax[index].set_ylabel('y', fontsize = 18)\n", "    ax[index].set_xlim(left = 0, right = 150)\n", "    ax[index].set_ylim(bottom = 0)\n", "    \n", "    ax[index].text(50, 10, \" y={:.2f}x+{:.2f} (R2={:.2f})\".format(m, b, score), fontsize = 12)\n", "\n", "ax[0].set_title('fit_intercept = True', fontsize = 20)   \n", "ax[1].set_title('fit_intercept = False',  fontsize = 20)    \n", "fig.tight_layout()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["So that's it, I encourage you to create a linear regression model using scikit-learn so you can have a better understanding how scikit-learn works. "]}, {"cell_type": "markdown", "metadata": {}, "source": "<hr><font color=\"green\"><h1>from file: 02_04_Train_Test_Split</h1></font>"}, {"cell_type": "markdown", "metadata": {}, "source": ["A goal of supervised learning is to build a model that performs well on new data. If you have new data, you could see how your model performs on it. The problem is that you may not have new data, but you can simulate this experience with a train test split. In this video, I'll show you how train test split works in Scikit-Learn."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## What is `train_test_split`"]}, {"cell_type": "markdown", "metadata": {}, "source": ["1. Split the dataset into two pieces: a **training set** and a **testing set**. Typically, about 75% of the data goes to your training set and 25% goes to your test set. \n", "2. Train the model on the **training set**.\n", "3. Test the model on the **testing set** and evaluate the performance \n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Import Libraries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%matplotlib inline\n", "\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "\n", "from sklearn.datasets import load_boston\n", "\n", "from sklearn.model_selection import train_test_split\n", "\n", "from sklearn.linear_model import LinearRegression"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load the Dataset\n", "The boston house-price dataset is one of datasets scikit-learn comes with that do not require the downloading of any file from some external website. The code below loads the boston dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = load_boston()\n", "df = pd.DataFrame(data.data, columns=data.feature_names)\n", "df['target'] = data.target\n", "df.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = df.loc[:, ['RM', 'LSTAT', 'PTRATIO']].values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y = df.loc[:, 'target'].values"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train Test Split "]}, {"cell_type": "markdown", "metadata": {}, "source": ["![images](images/trainTestSplitBoston.png)\n", "The colors in the image indicate which variable (X_train, X_test, y_train, y_test) the data from the dataframe df went to for a particular train test split (not necessarily the exact split of the code below)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Linear Regression Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Make a linear regression instance\n", "reg = LinearRegression(fit_intercept=True)\n", "\n", "# Train the model on the training set.\n", "reg.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Measuring Model Performance\n", "By measuring model performance on the test set, you can estimate how well your model is likely to perform on new data (out-of-sample data)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Test the model on the testing set and evaluate the performance\n", "score = reg.score(X_test, y_test)\n", "print(score)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["So that's it, train_test_split helps you simulate how well a model would perform on new data"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 2}